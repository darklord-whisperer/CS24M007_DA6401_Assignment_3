{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Visualization_Q6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importing the required packages\n",
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import cv2"
      ],
      "metadata": {
        "id": "cEozejXIZt12"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XsecTVDsXZMg"
      },
      "outputs": [],
      "source": [
        "# Downloading the datafile.\n",
        "%%capture\n",
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "!tar -xf dakshina_dataset_v1.0.tar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/dakshina_dataset_v1.0/hi/lexicons/* ./"
      ],
      "metadata": {
        "id": "HpUkOim-eBWg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"hi.translit.sampled.train.tsv\"\n",
        "dev_path = \"hi.translit.sampled.dev.tsv\"\n",
        "test_path = \"hi.translit.sampled.test.tsv\""
      ],
      "metadata": {
        "id": "BP21v9RxeDpR"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
      ],
      "metadata": {
        "id": "M_Y5v_bteGZz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading and preprocessing the data.\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "def load_data(path):\n",
        "    with open(path) as f:\n",
        "        data = pd.read_csv(f, sep='\\t',header=None,names=[\"indic\",\"english\",\"\"],skip_blank_lines=True,index_col=None)\n",
        "    data = data[data['indic'].notna()]\n",
        "    data = data[data['english'].notna()]\n",
        "    data = data[['indic','english']]\n",
        "    return data\n",
        "\n",
        "def preprocess(train_path, dev_path, test_path, batch_size):\n",
        "\n",
        "    train_df = load_data(train_path)\n",
        "    val_df = load_data(dev_path)\n",
        "    test_df = load_data(test_path)\n",
        "\n",
        "    train_indic = train_df['indic'].values\n",
        "    train_english = train_df['english'].values\n",
        "    val_indic = val_df['indic'].values\n",
        "    val_english = val_df['english'].values\n",
        "    test_indic = test_df['indic'].values\n",
        "    test_english = test_df['english'].values\n",
        "\n",
        "\n",
        "    # \"\\t\" is considered as the \"start\" character\n",
        "    # \"\\n\" is considered as the \"end\" character.\n",
        "\n",
        "    #We add the above characters to the indic transliterated words.\n",
        "    train_indic =  \"\\t\" + train_indic + \"\\n\"\n",
        "    val_indic =  \"\\t\" + val_indic + \"\\n\"\n",
        "    test_indic =  \"\\t\" + test_indic + \"\\n\"\n",
        "\n",
        "\n",
        "    #Create character sets for each language\n",
        "    indic_char_set = set()\n",
        "    english_char_set = set()\n",
        "\n",
        "    indic_char_set.add(' ')\n",
        "    english_char_set.add(' ')\n",
        "    \n",
        "    for word_english, word_indic in zip(train_english, train_indic):\n",
        "        for char in word_english:\n",
        "            english_char_set.add(char)\n",
        "        for char in word_indic:\n",
        "            indic_char_set.add(char)\n",
        "\n",
        "    english_char_set = sorted(list(english_char_set))\n",
        "    indic_char_set = sorted(list(indic_char_set))\n",
        "\n",
        "\n",
        "    #Create empty dicts.\n",
        "    english_char_to_idx = dict()\n",
        "    indic_char_to_idx = dict()\n",
        "\n",
        "    english_idx_to_char = dict()\n",
        "    indic_idx_to_char = dict()\n",
        "\n",
        "    #As our character sets don't consider spaces, we assign a special id -1 to space.\n",
        "    # We will pad the strings with spaces to make them of equal length, to support batchwise training.\n",
        "\n",
        "    english_char_to_idx[\" \"] = -1\n",
        "    indic_char_to_idx[\" \"] = -1\n",
        "\n",
        "    #Create a mapping of characters to indices    \n",
        "    for i, char in enumerate(english_char_set):\n",
        "        english_char_to_idx[char] = i\n",
        "\n",
        "    for i, char in enumerate(indic_char_set):\n",
        "        indic_char_to_idx[char] = i\n",
        "\n",
        "\n",
        "    #Create a mapping of indices to characters.\n",
        "\n",
        "    for char, idx in english_char_to_idx.items():\n",
        "        english_idx_to_char[idx] = char\n",
        "\n",
        "    for char, idx in indic_char_to_idx.items():\n",
        "        indic_idx_to_char[idx] = char\n",
        "    \n",
        "    #Find the max word length in the indic and english sentences respectively.\n",
        "\n",
        "    max_seq_len_english_encoder = max([len(word) for word in train_english])\n",
        "    max_seq_len_indic_decoder = max([len(word) for word in train_indic])\n",
        "\n",
        "    encoder_train_english = np.zeros((len(train_english), max_seq_len_english_encoder), dtype=\"float32\")\n",
        "    decoder_train_english = np.zeros((len(train_english), max_seq_len_indic_decoder), dtype=\"float32\")\n",
        "    decoder_train_indic = np.zeros(\n",
        "        (len(train_english), max_seq_len_indic_decoder, len(indic_char_set)), dtype=\"float32\"\n",
        "    )\n",
        "\n",
        "    encoder_val_english = np.zeros(\n",
        "        (len(val_english), max_seq_len_english_encoder), dtype=\"float32\"\n",
        "    )\n",
        "    decoder_val_english = np.zeros(\n",
        "        (len(val_english), max_seq_len_indic_decoder), dtype=\"float32\"\n",
        "    )\n",
        "    decoder_val_indic = np.zeros(\n",
        "        (len(val_english), max_seq_len_indic_decoder, len(indic_char_set)), dtype=\"float32\"\n",
        "    )\n",
        "\n",
        "    encoder_test_english = np.zeros(\n",
        "        (len(test_english), max_seq_len_english_encoder), dtype=\"float32\"\n",
        "    )\n",
        "    decoder_test_english = np.zeros(\n",
        "        (len(test_english), max_seq_len_indic_decoder), dtype=\"float32\"\n",
        "    )\n",
        "    decoder_test_indic = np.zeros(\n",
        "        (len(test_english), max_seq_len_indic_decoder, len(indic_char_set)), dtype=\"float32\"\n",
        "    )\n",
        "\n",
        "    # print(encoder_train_english.shape, \"ENC Train Eng\")\n",
        "    # print(decoder_train_english.shape, \"DEC Train Eng\")\n",
        "    # print(decoder_train_indic.shape, \"DEC Train Indic\")\n",
        "    # print(encoder_val_english.shape, \"ENC Val Eng\")\n",
        "    # print(decoder_val_english.shape, \"DEC Val Eng\")\n",
        "    # print(decoder_val_indic.shape, \"DEC Val Eng\")\n",
        "    # print(encoder_test_english.shape, \"ENC Test Eng\")\n",
        "    # print(decoder_test_english.shape, \"DEC Test Eng\")\n",
        "    # print(decoder_test_indic.shape, \"DEC Test Eng\")\n",
        "  \n",
        "\n",
        "    for i, (input_word, target_word) in enumerate(zip(train_english, train_indic)):\n",
        "        for t, char in enumerate(input_word):\n",
        "            #Replace character by its index.\n",
        "            encoder_train_english[i, t] = english_char_to_idx[char]\n",
        "        #Padding with zeros.\n",
        "        encoder_train_english[i, t + 1 :] = english_char_to_idx[' ']\n",
        "        \n",
        "        for t, char in enumerate(target_word):\n",
        "            decoder_train_english[i, t] = indic_char_to_idx[char]\n",
        "            if t > 0:\n",
        "                # Indic decoder will be ahead by one timestep.\n",
        "                decoder_train_indic[i, t - 1, indic_char_to_idx[char]] = 1.0\n",
        "        #Padding with spaces.\n",
        "        decoder_train_english[i, t + 1 :] = indic_char_to_idx[' ']\n",
        "        decoder_train_indic[i, t :, indic_char_to_idx[' ']] = 1.0\n",
        "\n",
        "\n",
        "    for i, (input_word, target_word) in enumerate(zip(val_english, val_indic)):\n",
        "        for t, char in enumerate(input_word):\n",
        "            #Replace character by its index.\n",
        "            encoder_val_english[i, t] = english_char_to_idx[char]\n",
        "        #Padding with zeros.\n",
        "        encoder_val_english[i, t + 1 :] = english_char_to_idx[' ']\n",
        "        \n",
        "        for t, char in enumerate(target_word):\n",
        "            decoder_val_english[i, t] = indic_char_to_idx[char]\n",
        "            if t > 0:\n",
        "                # Indic decoder will be ahead by one timestep.\n",
        "                decoder_val_indic[i, t - 1, indic_char_to_idx[char]] = 1.0\n",
        "        #Padding with spaces.\n",
        "        decoder_val_english[i, t + 1 :] = indic_char_to_idx[' ']\n",
        "        decoder_val_indic[i, t :, indic_char_to_idx[' ']] = 1.0\n",
        "\n",
        "    for i, (input_word, target_word) in enumerate(zip(test_english, test_indic)):\n",
        "        for t, char in enumerate(input_word):\n",
        "            #Replace character by its index.\n",
        "            encoder_test_english[i, t] = english_char_to_idx[char]\n",
        "        #Padding with spaces.\n",
        "        encoder_test_english[i, t + 1 :] = english_char_to_idx[' ']\n",
        "        \n",
        "        for t, char in enumerate(target_word):\n",
        "            decoder_test_english[i, t] = indic_char_to_idx[char]\n",
        "            if t > 0:\n",
        "                # Indic decoder will be ahead by one timestep.\n",
        "                decoder_test_indic[i, t - 1, indic_char_to_idx[char]] = 1.0\n",
        "        #Padding with spaces.\n",
        "        decoder_test_english[i, t + 1 :] = indic_char_to_idx[' ']\n",
        "        decoder_test_indic[i, t :, indic_char_to_idx[' ']] = 1.0\n",
        "\n",
        "\n",
        "    return (encoder_train_english, decoder_train_english, decoder_train_indic), (encoder_val_english, decoder_val_english, decoder_val_indic), (val_english, val_indic), (encoder_test_english, decoder_test_english, decoder_test_indic), (english_char_set, indic_char_set, max_seq_len_english_encoder, max_seq_len_indic_decoder), (indic_char_to_idx, indic_idx_to_char), (english_char_to_idx, english_idx_to_char)\n",
        "    \n",
        "\n",
        "#Reference : Keras Documentation.\n",
        "#https://keras.io/examples/nlp/lstm_seq2seq/\n",
        "#https://stackoverflow.com/questions/54176051/invalidargumenterror-indicesi-0-x-is-not-in-0-x-in-keras"
      ],
      "metadata": {
        "id": "UGkPdzGReRW1"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Input,LSTM,SimpleRNN,GRU,TimeDistributed,Embedding\n",
        "from tensorflow.keras.optimizers import Adam,Nadam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Concatenate, AdditiveAttention\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class Model(object):\n",
        "    def __init__(self, english_char_set, indic_char_set, max_seq_len_english_encoder, max_seq_len_indic_decoder, indic_char_to_idx, indic_idx_to_char, english_char_to_idx, english_idx_to_char, cell =\"LSTM\", optimizer = \"adam\", embedding_size = 32, num_enc_layers = 5, num_dec_layers =2, num_hidden_layers = 64, dropout = 0):\n",
        "        self.len_enc_charset = len(english_char_set)\n",
        "        self.len_dec_charset = len(indic_char_set)\n",
        "        self.max_seq_len_english_encoder = max_seq_len_english_encoder\n",
        "        self.max_seq_len_indic_decoder = max_seq_len_indic_decoder\n",
        "        self.indic_char_to_idx = indic_char_to_idx\n",
        "        self.indic_idx_to_char = indic_idx_to_char\n",
        "        self.english_char_to_idx = english_char_to_idx\n",
        "        self.english_idx_to_char = english_idx_to_char\n",
        "        self.cell = cell\n",
        "        self.embedding_size = embedding_size\n",
        "        self.num_enc_layers = num_enc_layers\n",
        "        self.num_dec_layers= num_dec_layers\n",
        "        self.num_hidden_layers =num_hidden_layers\n",
        "        self.encoder_model = None\n",
        "        self.decoder_model = None\n",
        "        self.model = None\n",
        "        self.dropout = dropout\n",
        "        self.num_epochs = None\n",
        "        self.batch_size = None\n",
        "        self.optimizer = optimizer\n",
        "        \n",
        "\n",
        "    def build_model(self):\n",
        "        encoder_inputs = Input(shape=(None,), name=\"encoder_input\")\n",
        "        encoder_outputs = Embedding(self.len_enc_charset, self.embedding_size, name = \"encoder_embedding\")(encoder_inputs)\n",
        "        self.enc_layers = []\n",
        "        self.dec_layers = []\n",
        "        encoder_states = list()\n",
        "        for j in range(self.num_enc_layers):\n",
        "            if self.cell == \"rnn\":\n",
        "                encoder = SimpleRNN(self.num_hidden_layers, dropout = self.dropout, return_state = True, return_sequences = True)\n",
        "                encoder_outputs, state = encoder(encoder_outputs)\n",
        "                encoder_states.append([state])\n",
        "                self.enc_layers.append(encoder)\n",
        "            if self.cell == \"lstm\":\n",
        "                encoder = LSTM(self.num_hidden_layers, dropout = self.dropout, return_state = True, return_sequences = True)\n",
        "                encoder_outputs, state_h, state_c = encoder(encoder_outputs)\n",
        "                encoder_states.append([state_h,state_c])\n",
        "                self.enc_layers.append(encoder)\n",
        "            if self.cell == \"gru\":\n",
        "                encoder = GRU(self.num_hidden_layers, dropout = self.dropout, return_state = True, return_sequences = True)\n",
        "                encoder_outputs, state = encoder(encoder_outputs)\n",
        "                encoder_states.append([state])\n",
        "                self.enc_layers.append(encoder)\n",
        "\n",
        "        self.encoder_model = keras.Model(encoder_inputs,encoder_states)\n",
        "\n",
        "        decoder_inputs = keras.Input(shape=(self.max_seq_len_indic_decoder, ), name = \"decoder_input\")\n",
        "      \n",
        "        decoder_outputs = Embedding(self.len_dec_charset, self.embedding_size, name = \"decoder_embedding\")(decoder_inputs)\n",
        "        decoder_states = list()\n",
        "\n",
        "        for j in range(self.num_dec_layers):\n",
        "            if self.cell == \"rnn\":\n",
        "                decoder = SimpleRNN(self.num_hidden_layers, dropout = self.dropout, return_sequences = True, return_state = True)\n",
        "                decoder_outputs, state = decoder(decoder_outputs, initial_state = encoder_states[j])\n",
        "                decoder_states.append([state])\n",
        "                self.dec_layers.append(decoder)\n",
        "            if self.cell == \"lstm\":\n",
        "                decoder = LSTM(self.num_hidden_layers, dropout = self.dropout, return_sequences = True, return_state = True)\n",
        "                decoder_outputs, state_h, state_c = decoder(decoder_outputs, initial_state = encoder_states[j])\n",
        "                decoder_states.append([state_h, state_c])\n",
        "                self.dec_layers.append(decoder)\n",
        "            if self.cell == \"gru\":\n",
        "                decoder = GRU(self.num_hidden_layers, dropout = self.dropout, return_sequences = True, return_state = True)\n",
        "                decoder_outputs, state = decoder(decoder_outputs, initial_state = encoder_states[j])\n",
        "                decoder_states.append([state])\n",
        "                self.dec_layers.append(decoder)\n",
        "\n",
        "        decoder_attn = AdditiveAttention(name=\"attention_layer\")\n",
        "        decoder_concat = Concatenate(name=\"concatenate_layer\")\n",
        "        cont_vec, attn_wts = decoder_attn([decoder_outputs, encoder_outputs],return_attention_scores=True)\n",
        "        decoder_outputs = decoder_concat([decoder_outputs,cont_vec])\n",
        "        \n",
        "        dec_dense =Dense(self.len_dec_charset, activation=\"softmax\", name=\"dense_layer\")\n",
        "        dec_pred = dec_dense(decoder_outputs)\n",
        "            \n",
        "        \n",
        "        model = keras.Model([encoder_inputs, decoder_inputs], dec_pred)\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=self.optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "        )\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "\n",
        "    def train(self, encoder_train_english, decoder_train_english, decoder_train_indic, encoder_val_english, decoder_val_english, decoder_val_indic, num_epochs =10, batch_size = 64):\n",
        "        self.num_epochs = num_epochs\n",
        "        self.batch_size = batch_size\n",
        "        self.model.fit(\n",
        "        x = [encoder_train_english, decoder_train_english],\n",
        "        y = decoder_train_indic,\n",
        "        validation_data = ([encoder_val_english, decoder_val_english], decoder_val_indic),\n",
        "        batch_size = self.batch_size,\n",
        "        epochs = self.num_epochs,\n",
        "        # callbacks = [WandbCallback()]\n",
        "        )  \n",
        "\n",
        "    def inference_setup(self):\n",
        "    \n",
        "        encoder_inputs = self.model.input[0]\n",
        "\n",
        "        enc_embed_layer = self.model.get_layer('encoder_embedding')\n",
        "\n",
        "        encoder_outputs = enc_embed_layer(encoder_inputs)\n",
        "\n",
        "        encoder_states = []\n",
        "\n",
        "        if self.cell == 'rnn':\n",
        "            for i in range(self.num_enc_layers):\n",
        "                encoder_outputs, state_h = self.enc_layers[i](encoder_outputs)\n",
        "                encoder_states += [state_h] \n",
        "        elif self.cell == 'lstm':\n",
        "            for i in range(self.num_enc_layers):\n",
        "                encoder_outputs, state_h, state_c = self.enc_layers[i](encoder_outputs)\n",
        "                encoder_states += [state_h, state_c]   \n",
        "        elif self.cell == 'gru':\n",
        "            for i in range(self.num_enc_layers):\n",
        "                encoder_outputs, state_h = self.enc_layers[i](encoder_outputs)\n",
        "                encoder_states += [state_h] \n",
        "\n",
        "        self.encoder_model = keras.Model(encoder_inputs, encoder_states + [encoder_outputs])\n",
        "\n",
        "\n",
        "        decoder_inputs = self.model.input[1]    \n",
        "        dec_embed_layer = self.model.get_layer('decoder_embedding')\n",
        "        decoder_outputs = dec_embed_layer(decoder_inputs)\n",
        "\n",
        "        dec_states = []\n",
        "        dec_initial_states = []\n",
        "        \n",
        "        if self.cell == 'lstm' :\n",
        "            j=0\n",
        "            for i in range(self.num_dec_layers):\n",
        "                dec_initial_states += [Input(shape=(self.num_hidden_layers, )) , Input(shape=(self.num_hidden_layers, ))]\n",
        "                decoder_outputs, state_h, state_c = self.dec_layers[i](decoder_outputs, initial_state=dec_initial_states[i+j:i+j+2])\n",
        "                dec_states += [state_h , state_c]\n",
        "                j += 1\n",
        "\n",
        "        else:\n",
        "            for i in range(self.num_dec_layers):\n",
        "                dec_initial_states += [Input(shape=(self.num_hidden_layers,))]\n",
        "                decoder_outputs, state_h = self.dec_layers[i](decoder_outputs, initial_state = dec_initial_states[i])\n",
        "                dec_states += [state_h]\n",
        "\n",
        "        attention_layer = self.model.get_layer('attention_layer')\n",
        "\n",
        "        attention_input = Input(shape=(self.max_seq_len_english_encoder,self.num_hidden_layers))   \n",
        "\n",
        "        context_vector, alphas = attention_layer([decoder_outputs, attention_input], return_attention_scores=True)\n",
        "    \n",
        "        concat_layer = self.model.get_layer('concatenate_layer')\n",
        "\n",
        "        decoder_outputs = concat_layer([decoder_outputs, context_vector])\n",
        "\n",
        "\n",
        "        # Dense layer\n",
        "        decoder_dense = self.model.get_layer('dense_layer')\n",
        "\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "        # Decoder model\n",
        "        self.decoder_model = keras.Model(\n",
        "            [decoder_inputs] + dec_initial_states + [attention_input], [decoder_outputs] + dec_states + [alphas])\n",
        "\n",
        "    def decode_sequence(self, input_seq):\n",
        "        self.inference_setup()\n",
        "        enc_states = self.encoder_model.predict(input_seq)\n",
        "        attention_input = enc_states[-1]\n",
        "\n",
        "        enc_states = enc_states[:-1]\n",
        "        \n",
        "        target_seq = np.zeros((1, 1)) \n",
        "        target_seq[0, 0] = self.indic_char_to_idx[\"\\t\"]\n",
        "        \n",
        "        attention_weights = []\n",
        "        stop_condition = False\n",
        "        decoded_sentence = \"\"\n",
        "        while not stop_condition:\n",
        "            output_tokens = self.decoder_model.predict([target_seq] + enc_states + [attention_input])\n",
        "            sampled_token_index = np.argmax(output_tokens[0][0, -1, :])\n",
        "            sampled_char = self.indic_idx_to_char[sampled_token_index]\n",
        "            decoded_sentence += sampled_char\n",
        "\n",
        "            if sampled_char == \"\\n\" or len(decoded_sentence) > self.max_seq_len_indic_decoder:\n",
        "                stop_condition = True\n",
        "\n",
        "            target_seq = np.zeros((1, 1))\n",
        "            target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "            enc_states = output_tokens[1:-1]\n",
        "            attention_weights.append(output_tokens[-1][0][0])\n",
        "            \n",
        "        return decoded_sentence, attention_weights\n"
      ],
      "metadata": {
        "id": "gDJf5wFyeY-H"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(encoder_train_english, decoder_train_english, decoder_train_indic), (encoder_val_english, decoder_val_english, decoder_val_indic), (val_english, val_indic), (encoder_test_english, decoder_test_english, decoder_test_indic), (english_char_set, indic_char_set, max_seq_len_english_encoder, max_seq_len_indic_decoder), (indic_char_to_idx, indic_idx_to_char), (english_char_to_idx, english_idx_to_char) = preprocess(train_path, dev_path, test_path, batch_size = 128)  "
      ],
      "metadata": {
        "id": "BMdpwCfb9tqP"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a RNN-model\n",
        "rnn_model =  Model(english_char_set, indic_char_set, max_seq_len_english_encoder, max_seq_len_indic_decoder, indic_char_to_idx, indic_idx_to_char, english_char_to_idx, english_idx_to_char, cell = 'gru', optimizer = \"adam\", embedding_size = 512, num_enc_layers = 1, num_dec_layers = 1, num_hidden_layers = 256, dropout = 0.2)\n",
        "\n",
        "rnn_model.build_model()\n",
        "\n",
        "rnn_model.train(encoder_train_english, decoder_train_english, decoder_train_indic, encoder_val_english, decoder_val_english, decoder_val_indic, num_epochs = 10, batch_size = 128)\n"
      ],
      "metadata": {
        "id": "c65eqMf_bqmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037aaa28-1098-47df-9bd2-8e3cd16771a7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "346/346 [==============================] - 30s 47ms/step - loss: 0.9142 - accuracy: 0.7640 - val_loss: 0.4430 - val_accuracy: 0.8710\n",
            "Epoch 2/10\n",
            "346/346 [==============================] - 15s 44ms/step - loss: 0.2849 - accuracy: 0.9118 - val_loss: 0.2013 - val_accuracy: 0.9361\n",
            "Epoch 3/10\n",
            "346/346 [==============================] - 15s 44ms/step - loss: 0.1781 - accuracy: 0.9429 - val_loss: 0.1664 - val_accuracy: 0.9467\n",
            "Epoch 4/10\n",
            "346/346 [==============================] - 15s 43ms/step - loss: 0.1484 - accuracy: 0.9526 - val_loss: 0.1501 - val_accuracy: 0.9513\n",
            "Epoch 5/10\n",
            "346/346 [==============================] - 15s 43ms/step - loss: 0.1309 - accuracy: 0.9579 - val_loss: 0.1454 - val_accuracy: 0.9530\n",
            "Epoch 6/10\n",
            "346/346 [==============================] - 15s 43ms/step - loss: 0.1186 - accuracy: 0.9619 - val_loss: 0.1406 - val_accuracy: 0.9541\n",
            "Epoch 7/10\n",
            "346/346 [==============================] - 15s 43ms/step - loss: 0.1086 - accuracy: 0.9651 - val_loss: 0.1389 - val_accuracy: 0.9550\n",
            "Epoch 8/10\n",
            "346/346 [==============================] - 15s 43ms/step - loss: 0.1004 - accuracy: 0.9678 - val_loss: 0.1347 - val_accuracy: 0.9572\n",
            "Epoch 9/10\n",
            "346/346 [==============================] - 15s 43ms/step - loss: 0.0929 - accuracy: 0.9700 - val_loss: 0.1353 - val_accuracy: 0.9573\n",
            "Epoch 10/10\n",
            "346/346 [==============================] - 15s 43ms/step - loss: 0.0859 - accuracy: 0.9723 - val_loss: 0.1383 - val_accuracy: 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choosing the colour based on attention weight.\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.font_manager import FontProperties\n",
        "from IPython.display import HTML as html_print\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def cstr(s, color='black'):\n",
        "    if s == ' ':\n",
        "        return \"<text style=color:#000;padding-left:10px;background-color:{}> </text>\".format(color, s)\n",
        "    else:\n",
        "        return \"<text style=color:#000;background-color:{}>{} </text>\".format(color, s)\n",
        "\t\n",
        "def print_color(t):\n",
        "    display(html_print(''.join([cstr(ti, color=ci) for ti,ci in t])))\n",
        "\n",
        "def get_clr(value):\n",
        "    colors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8',\n",
        "    '#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8',\n",
        "    '#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f',\n",
        "    '#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']      \n",
        "    value = min(int((value * 100) / 5), 19)\n",
        "    return colors[value]"
      ],
      "metadata": {
        "id": "kQ7gnPrLhml4"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize(attention,output, input, cell_no):\n",
        "  text_colours = []\n",
        "  for i in range(len(input)):\n",
        "    text = (input[i], get_clr(attention[cell_no][i]))\n",
        "    text_colours.append(text)\n",
        "  return text_colours\n",
        "  "
      ],
      "metadata": {
        "id": "OBymcYEphodW"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the test dataset words at index idx.\n",
        "#These samples I manually picked\n",
        "idx = [200,250,300,1543]\n",
        "\n",
        "predictions = []\n",
        "attentions= []\n",
        "result = {}\n",
        "test_df = load_data(test_path)\n",
        "test_indic = test_df['indic'].values\n",
        "rnn_model.inference_setup()\n",
        "test_eng = test_df['english'].values\n",
        "attention_gap = [2, 5, 8, 10, 12,15,18,20]\n",
        "for index in idx:   # For each input to analyse\n",
        "  input_seq = encoder_test_english[index:index+1]\n",
        "  output, attn_weights = rnn_model.decode_sequence(input_seq)\n",
        "  # print(test_eng[i],input_seq, test_indic[i].strip(), output.strip())\n",
        "  # print(\"attention\",attn_weights,len(attn_weights),test_eng[i],)\n",
        "  predictions.append(output)\n",
        "  attentions.append(attn_weights)\n",
        "  res = []\n",
        "  print('***************************')\n",
        "  print()\n",
        "  print( output.strip(), \"<=\",test_eng[index])\n",
        "  for i in range(len(output.strip())):\n",
        "    text_colours = visualize(attn_weights,output.strip(),test_eng[index],i)\n",
        "    print(output.strip()[i])\n",
        "    print_color(text_colours)\n",
        "    res.append((output.strip()[i],text_colours))\n",
        "  result[output.strip()+\"=>\"+test_eng[index]]=res\n",
        "  print()\n",
        "  print('***************************')\n",
        "  print()\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_M-v6-Pd-aht",
        "outputId": "0786a497-5ec7-406e-a0f8-bdc3cfcb1aa3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 21) for input KerasTensor(type_spec=TensorSpec(shape=(None, 21), dtype=tf.float32, name='decoder_input'), name='decoder_input', description=\"created by layer 'decoder_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
            "***************************\n",
            "\n",
            "अवरू <= avaru\n",
            "अ\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#f8a8a8>a </text><text style=color:#000;background-color:#b2d9ec>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "व\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#f68f8f>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#85c2e1>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "र\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#89c4e2>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#baddee>r </text><text style=color:#000;background-color:#baddee>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ू\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>v </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#f8a8a8>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "***************************\n",
            "\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 21) for input KerasTensor(type_spec=TensorSpec(shape=(None, 21), dtype=tf.float32, name='decoder_input'), name='decoder_input', description=\"created by layer 'decoder_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
            "***************************\n",
            "\n",
            "इट्यू <= item\n",
            "इ\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#eff7fb>i </text><text style=color:#000;background-color:#f9e8e8>t </text><text style=color:#000;background-color:#85c2e1>e </text><text style=color:#000;background-color:#85c2e1>m </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ट\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#f45f5f>t </text><text style=color:#000;background-color:#89c4e2>e </text><text style=color:#000;background-color:#85c2e1>m </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "्\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#99cce6>t </text><text style=color:#000;background-color:#99cce6>e </text><text style=color:#000;background-color:#99cce6>m </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "य\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#a1d0e8>t </text><text style=color:#000;background-color:#b2d9ec>e </text><text style=color:#000;background-color:#99cce6>m </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ू\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#95cae5>t </text><text style=color:#000;background-color:#89c4e2>e </text><text style=color:#000;background-color:#a1d0e8>m </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "***************************\n",
            "\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 21) for input KerasTensor(type_spec=TensorSpec(shape=(None, 21), dtype=tf.float32, name='decoder_input'), name='decoder_input', description=\"created by layer 'decoder_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
            "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f820ba75560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "***************************\n",
            "\n",
            "आब्रु <= aabru\n",
            "आ\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#b2d9ec>a </text><text style=color:#000;background-color:#eff7fb>a </text><text style=color:#000;background-color:#99cce6>b </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#85c2e1>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ब\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#89c4e2>a </text><text style=color:#000;background-color:#f9d4d4>b </text><text style=color:#000;background-color:#b2d9ec>r </text><text style=color:#000;background-color:#85c2e1>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "्\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#89c4e2>b </text><text style=color:#000;background-color:#f47676>r </text><text style=color:#000;background-color:#89c4e2>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "र\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#89c4e2>b </text><text style=color:#000;background-color:#f45f5f>r </text><text style=color:#000;background-color:#89c4e2>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ु\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>b </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#f9bdbd>u </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "***************************\n",
            "\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 21) for input KerasTensor(type_spec=TensorSpec(shape=(None, 21), dtype=tf.float32, name='decoder_input'), name='decoder_input', description=\"created by layer 'decoder_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
            "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f820b84ccb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "***************************\n",
            "\n",
            "ट्रांजिस्टर <= trangistor\n",
            "ट\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#f9d4d4>t </text><text style=color:#000;background-color:#c2e1f0>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>o </text><text style=color:#000;background-color:#85c2e1>r </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "्\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#f9bdbd>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#89c4e2>n </text><text style=color:#000;background-color:#95cae5>g </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>o </text><text style=color:#000;background-color:#85c2e1>r </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "र\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#95cae5>t </text><text style=color:#000;background-color:#f68f8f>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#89c4e2>n </text><text style=color:#000;background-color:#89c4e2>g </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>o </text><text style=color:#000;background-color:#85c2e1>r </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ा\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#eff7fb>n </text><text style=color:#000;background-color:#c2e1f0>g </text><text style=color:#000;background-color:#89c4e2>i </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>o </text><text style=color:#000;background-color:#85c2e1>r </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ं\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#eff7fb>n </text><text style=color:#000;background-color:#baddee>g </text><text style=color:#000;background-color:#89c4e2>i </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>o </text><text style=color:#000;background-color:#85c2e1>r </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ज\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#89c4e2>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#a1d0e8>n </text><text style=color:#000;background-color:#f9e8e8>g </text><text style=color:#000;background-color:#95cae5>i </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>o </text><text style=color:#000;background-color:#85c2e1>r </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ि\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#89c4e2>g </text><text style=color:#000;background-color:#f9d4d4>i </text><text style=color:#000;background-color:#95cae5>s </text><text style=color:#000;background-color:#95cae5>t </text><text style=color:#000;background-color:#85c2e1>o </text><text style=color:#000;background-color:#85c2e1>r </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "स\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#95cae5>i </text><text style=color:#000;background-color:#f9d4d4>s </text><text style=color:#000;background-color:#a1d0e8>t </text><text style=color:#000;background-color:#85c2e1>o </text><text style=color:#000;background-color:#85c2e1>r </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "्\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#89c4e2>s </text><text style=color:#000;background-color:#f8a8a8>t </text><text style=color:#000;background-color:#89c4e2>o </text><text style=color:#000;background-color:#89c4e2>r </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ट\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#89c4e2>s </text><text style=color:#000;background-color:#f9bdbd>t </text><text style=color:#000;background-color:#95cae5>o </text><text style=color:#000;background-color:#89c4e2>r </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "र\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<text style=color:#000;background-color:#85c2e1>t </text><text style=color:#000;background-color:#85c2e1>r </text><text style=color:#000;background-color:#85c2e1>a </text><text style=color:#000;background-color:#85c2e1>n </text><text style=color:#000;background-color:#85c2e1>g </text><text style=color:#000;background-color:#85c2e1>i </text><text style=color:#000;background-color:#85c2e1>s </text><text style=color:#000;background-color:#89c4e2>t </text><text style=color:#000;background-color:#89c4e2>o </text><text style=color:#000;background-color:#c2e1f0>r </text>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "***************************\n",
            "\n",
            "{'अवरू=>avaru': [('अ', [('a', '#f8a8a8'), ('v', '#b2d9ec'), ('a', '#85c2e1'), ('r', '#85c2e1'), ('u', '#85c2e1')]), ('व', [('a', '#89c4e2'), ('v', '#f68f8f'), ('a', '#85c2e1'), ('r', '#89c4e2'), ('u', '#85c2e1')]), ('र', [('a', '#85c2e1'), ('v', '#89c4e2'), ('a', '#85c2e1'), ('r', '#baddee'), ('u', '#baddee')]), ('ू', [('a', '#85c2e1'), ('v', '#85c2e1'), ('a', '#85c2e1'), ('r', '#85c2e1'), ('u', '#f8a8a8')])], 'इट्यू=>item': [('इ', [('i', '#eff7fb'), ('t', '#f9e8e8'), ('e', '#85c2e1'), ('m', '#85c2e1')]), ('ट', [('i', '#85c2e1'), ('t', '#f45f5f'), ('e', '#89c4e2'), ('m', '#85c2e1')]), ('्', [('i', '#85c2e1'), ('t', '#99cce6'), ('e', '#99cce6'), ('m', '#99cce6')]), ('य', [('i', '#85c2e1'), ('t', '#a1d0e8'), ('e', '#b2d9ec'), ('m', '#99cce6')]), ('ू', [('i', '#85c2e1'), ('t', '#95cae5'), ('e', '#89c4e2'), ('m', '#a1d0e8')])], 'आब्रु=>aabru': [('आ', [('a', '#b2d9ec'), ('a', '#eff7fb'), ('b', '#99cce6'), ('r', '#89c4e2'), ('u', '#85c2e1')]), ('ब', [('a', '#85c2e1'), ('a', '#89c4e2'), ('b', '#f9d4d4'), ('r', '#b2d9ec'), ('u', '#85c2e1')]), ('्', [('a', '#85c2e1'), ('a', '#85c2e1'), ('b', '#89c4e2'), ('r', '#f47676'), ('u', '#89c4e2')]), ('र', [('a', '#85c2e1'), ('a', '#85c2e1'), ('b', '#89c4e2'), ('r', '#f45f5f'), ('u', '#89c4e2')]), ('ु', [('a', '#85c2e1'), ('a', '#85c2e1'), ('b', '#85c2e1'), ('r', '#89c4e2'), ('u', '#f9bdbd')])], 'ट्रांजिस्टर=>trangistor': [('ट', [('t', '#f9d4d4'), ('r', '#c2e1f0'), ('a', '#85c2e1'), ('n', '#85c2e1'), ('g', '#85c2e1'), ('i', '#85c2e1'), ('s', '#85c2e1'), ('t', '#85c2e1'), ('o', '#85c2e1'), ('r', '#85c2e1')]), ('्', [('t', '#89c4e2'), ('r', '#f9bdbd'), ('a', '#85c2e1'), ('n', '#89c4e2'), ('g', '#95cae5'), ('i', '#85c2e1'), ('s', '#85c2e1'), ('t', '#85c2e1'), ('o', '#85c2e1'), ('r', '#85c2e1')]), ('र', [('t', '#95cae5'), ('r', '#f68f8f'), ('a', '#85c2e1'), ('n', '#89c4e2'), ('g', '#89c4e2'), ('i', '#85c2e1'), ('s', '#85c2e1'), ('t', '#85c2e1'), ('o', '#85c2e1'), ('r', '#85c2e1')]), ('ा', [('t', '#85c2e1'), ('r', '#89c4e2'), ('a', '#85c2e1'), ('n', '#eff7fb'), ('g', '#c2e1f0'), ('i', '#89c4e2'), ('s', '#85c2e1'), ('t', '#85c2e1'), ('o', '#85c2e1'), ('r', '#85c2e1')]), ('ं', [('t', '#85c2e1'), ('r', '#89c4e2'), ('a', '#85c2e1'), ('n', '#eff7fb'), ('g', '#baddee'), ('i', '#89c4e2'), ('s', '#85c2e1'), ('t', '#85c2e1'), ('o', '#85c2e1'), ('r', '#85c2e1')]), ('ज', [('t', '#85c2e1'), ('r', '#89c4e2'), ('a', '#85c2e1'), ('n', '#a1d0e8'), ('g', '#f9e8e8'), ('i', '#95cae5'), ('s', '#85c2e1'), ('t', '#85c2e1'), ('o', '#85c2e1'), ('r', '#85c2e1')]), ('ि', [('t', '#85c2e1'), ('r', '#85c2e1'), ('a', '#85c2e1'), ('n', '#85c2e1'), ('g', '#89c4e2'), ('i', '#f9d4d4'), ('s', '#95cae5'), ('t', '#95cae5'), ('o', '#85c2e1'), ('r', '#85c2e1')]), ('स', [('t', '#85c2e1'), ('r', '#85c2e1'), ('a', '#85c2e1'), ('n', '#85c2e1'), ('g', '#85c2e1'), ('i', '#95cae5'), ('s', '#f9d4d4'), ('t', '#a1d0e8'), ('o', '#85c2e1'), ('r', '#85c2e1')]), ('्', [('t', '#85c2e1'), ('r', '#85c2e1'), ('a', '#85c2e1'), ('n', '#85c2e1'), ('g', '#85c2e1'), ('i', '#85c2e1'), ('s', '#89c4e2'), ('t', '#f8a8a8'), ('o', '#89c4e2'), ('r', '#89c4e2')]), ('ट', [('t', '#85c2e1'), ('r', '#85c2e1'), ('a', '#85c2e1'), ('n', '#85c2e1'), ('g', '#85c2e1'), ('i', '#85c2e1'), ('s', '#89c4e2'), ('t', '#f9bdbd'), ('o', '#95cae5'), ('r', '#89c4e2')]), ('र', [('t', '#85c2e1'), ('r', '#85c2e1'), ('a', '#85c2e1'), ('n', '#85c2e1'), ('g', '#85c2e1'), ('i', '#85c2e1'), ('s', '#85c2e1'), ('t', '#89c4e2'), ('o', '#89c4e2'), ('r', '#c2e1f0')])]}\n"
          ]
        }
      ]
    }
  ]
}